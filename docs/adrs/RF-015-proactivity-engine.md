# ADR RF-015: ProactivityEngine Implementation

**Status**: üü¢ OPERACIONAL (Phase 9 Validado)
**Data**: 2025-10-09
**Decisor**: CODEx Phase 9

---

## üìã Contexto

O requisito **RF-015** exige um motor proativo capaz de monitorar prazos e eventos para acionar notifica√ß√µes sem interven√ß√£o do usu√°rio. As fases anteriores documentaram o plano, por√©m o worker ainda n√£o existia em produ√ß√£o. Durante a Phase 9 o objetivo foi entregar a funda√ß√£o operacional desse motor com monitoramento, DLQ e m√©tricas prontas para observabilidade em Grafana/Prometheus.

---

## ‚úÖ Decis√£o

1. **Worker dedicado**: executar o ProactivityEngine em um servi√ßo pr√≥prio (`services/worker/app.py`) usando FastAPI + APScheduler.
2. **Monitoramento centralizado**: capturar execu√ß√µes via `EventMonitor` com persist√™ncia em PostgreSQL (`worker_job_events`).
3. **Gest√£o de falhas**: enfileirar exce√ß√µes em uma DLQ relacional (`worker_dlq`) com possibilidade futura de reprocessamento.
4. **Observabilidade nativa**: expor `/healthz` e `/metrics` diretamente no worker, incluindo m√©tricas `sparkone_worker_job_count_total` e `sparkone_worker_job_latency_seconds`.
5. **Infra integrada**: atualizar `docker-compose.yml` para subir o worker com probes de sa√∫de e expor a porta 9100 para m√©tricas.

---

## üõ†Ô∏è Implementa√ß√£o

### Componentes Principais
- **Worker App** (`services/worker/app.py`)
  - FastAPI com lifecycle que inicializa APScheduler (timezone `settings.timezone`).
  - Jobs agendados a cada 5 minutos (`event-reminder`, `task-reminder`) executados imediatamente no boot para popular m√©tricas/registros.
  - Instrumenta√ß√£o Prometheus e logs estruturados via `structlog`.
- **EventMonitor** (`services/worker/event_monitor.py`)
  - Registra execu√ß√µes na tabela `worker_job_events` (status, dura√ß√£o, payload, erro).
  - Emite logs estruturados `worker_job_event` com preview de payload.
- **NotificationManager** (`services/worker/notification_manager.py`)
  - Stub s√≠ncrono que persiste falhas na tabela `worker_dlq` e gera alertas em log (`worker_alert_dispatched`).
  - Preparado para integrar canais reais (WhatsApp/E-mail) sem bloquear o scheduler.

### Dead Letter Queue e Auditoria
- Arquivo de refer√™ncia SQL: `services/worker/dlq.sql`.
- Migra√ß√£o Alembic `1bc0f6b6be41_add_worker_tables` cria:
  - `worker_dlq(id, job_name, payload, error_message, scheduled_for, retry_count, created_at, processed_at)`.
  - `worker_job_events(id, job_name, status, scheduled_at, started_at, finished_at, runtime_seconds, payload, error_message, created_at)`.
- √çndices em `job_name` e colunas temporais aceleram filtros operacionais.

### Observabilidade
- Prometheus:
  - `sparkone_worker_job_count_total{job_name,status}`
  - `sparkone_worker_job_latency_seconds{job_name}`
- Endpoints expostos na porta 9100:
  - `GET /healthz` ‚Üí lista IDs dos jobs ativos.
  - `GET /metrics` ‚Üí payload compat√≠vel com Prometheus (& Grafana dashboards existentes).
- Logs: todos os registros usam JSON via `structlog` (eventos `worker_job_succeeded`, `worker_job_event`, `worker_dlq_enqueued`).

### Docker Compose
```yaml
docker-compose.yml
  worker:
    command: uvicorn services.worker.app:app --host 0.0.0.0 --port 9100
    ports:
      - "9100:9100"
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:9100/healthz')\""]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
```

---

## üîé Opera√ß√£o

| Item | Detalhe |
|------|---------|
| Jobs | `event-reminder` (eventos at√© +60 min), `task-reminder` (tarefas at√© +90 min) |
| Armazenamento | PostgreSQL (`worker_job_events`, `worker_dlq`) |
| Alertas | Logs estruturados ‚Üí Grafana/Loki |
| M√©tricas | Prometheus ‚Üí dashboards "Worker / Phase 9" |
| Reprocessamento | Manual (consultar `worker_dlq`, mover payload) |

### Fluxo de Execu√ß√£o
1. Scheduler dispara job (`IntervalTrigger` 5 min, `coalesce=True`).
2. Handler consulta banco ass√≠ncrono (`AsyncSession`).
3. Se encontrar itens:
   - Emite alerta via `NotificationManager.send_alert` (log, metadata com preview).
4. Ao finalizar:
   - `EventMonitor` persiste auditoria.
   - M√©tricas s√£o atualizadas (contador + histograma).
5. Em erro:
   - Payload/erro vai para `worker_dlq`.
   - Log estrutural `worker_dlq_enqueued` + alerta cr√≠tico.

---

## üìä Valida√ß√£o Fase 9
- Jobs executados e registrados nas tabelas (`worker_job_events` conta >= 2 entradas).
- M√©tricas `/metrics` exibem `sparkone_worker_job_count_total` e `sparkone_worker_job_latency_seconds` para ambos os jobs.
- Alertas vis√≠veis no stack de observabilidade (Grafana/Loki) via campos `job_name`, `severity`.
- Healthcheck do container aprovado (Docker reports `healthy`).

---

## ‚ö†Ô∏è Riscos & Pr√≥ximos Passos

| Risco | Mitiga√ß√£o |
|-------|-----------|
| Notifica√ß√µes reais ainda s√£o stubs | Integrar `NotificationManager` com Evolution API / e-mail antes do GA |
| Crescimento do DLQ | Criar rotina de reprocessamento peri√≥dico ou painel operacional |
| Cobertura de testes limitada | Adicionar testes de integra√ß√£o para jobs e migrations |

### Sugest√µes Futuras
1. Habilitar notifica√ß√£o multi-canal real (`NotificationManager`).
2. Adicionar job de brief di√°rio + integra√ß√£o com Evolution WhatsApp.
3. Expor API para reprocessar itens da DLQ.
4. Construir dashboard Grafana dedicado (lat√™ncia, falhas, backlog DLQ).

---

**Status Final**: ‚úÖ Motor proativo operacional com worker dedicado, DLQ e m√©tricas integradas.

**Respons√°vel**: CODEx Phase 9 Worker Team
