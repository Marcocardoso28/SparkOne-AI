{
  "permissions": {
    "allow": [
      "mcp__sequential-thinking-tools__sequentialthinking_tools",
      "mcp__context-7__resolve-library-id",
      "mcp__context-7__get-library-docs",
      "mcp__exa-search__web_search_exa",
      "Bash(find:*)",
      "Bash(pytest:*)",
      "mcp__ide__getDiagnostics",
      "Bash(venv\\Scripts\\activate:*)",
      "Bash(.venvScriptsactivate)",
      "Bash(source:*)",
      "Bash(pip install:*)",
      "Bash(PYTHONPATH=. pytest tests/smoke/test_health.py)",
      "Bash(make:*)",
      "Bash(python -m black:*)",
      "Bash(python:*)",
      "Bash(PYTHONPATH=. python -m pytest --cov=src --cov-report=term-missing)",
      "Bash(tree:*)",
      "Bash(PYTHONPATH=. python -m pytest --collect-only -q)",
      "Bash(docker:*)",
      "Bash(dir:*)",
      "Bash(findstr:*)",
      "Read(//c/Users/marco/AppData/Roaming/Claude/**)",
      "Bash(pip-audit:*)",
      "Bash(pip show:*)",
      "WebSearch",
      "Bash(cat:*)",
      "Bash(curl:*)",
      "Bash(del \"C:\\Users\\marco\\Macspark\\SparkOne\\test_message_flow.py\")",
      "Bash(git add:*)",
      "Bash(git commit -m \"$(cat <<''EOF''\nfix: Corrige upload de imagens e otimiza sistema de resposta\n\n- Corrige endpoint do formulÃ¡rio para /web/ingest (upload de imagens funcionando)\n- Implementa router inteligente de modelos LLM para melhor performance  \n- Adiciona sistema de cache para respostas mais rÃ¡pidas\n- Melhora prompts para maior inteligÃªncia nas respostas\n- Otimiza pipeline de processamento (embeddings assÃ­ncronos)\n- Corrige configuraÃ§Ãµes OpenAI (modelo gpt-4o-mini)\n- Implementa seleÃ§Ã£o automÃ¡tica entre modelos rÃ¡pidos e inteligentes\n- Adiciona fallback automÃ¡tico entre OpenAI e Ollama\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")",
      "Bash(git push:*)"
    ],
    "deny": [],
    "ask": []
  }
}